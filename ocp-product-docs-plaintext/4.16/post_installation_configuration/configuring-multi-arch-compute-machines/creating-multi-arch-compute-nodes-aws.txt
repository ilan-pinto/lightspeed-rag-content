# Creating a cluster with multi-architecture compute machines on AWS


To create an AWS cluster with multi-architecture compute machines, you must first create a single-architecture AWS installer-provisioned cluster with the multi-architecture installer binary. For more information on AWS installations, refer to Installing a cluster on AWS with customizations. You can then add a ARM64 compute machine set to your AWS cluster.

# Verifying cluster compatibility

Before you can start adding compute nodes of different architectures to your cluster, you must verify that your cluster is multi-architecture compatible.

* You installed the OpenShift CLI (oc)

* You can check that your cluster uses the architecture payload by running the following command:

```terminal
$ oc adm release info -o jsonpath="{ .metadata.metadata}"
```


1. If you see the following output, then your cluster is using the multi-architecture payload:

```terminal
{
 "release.openshift.io/architecture": "multi",
 "url": "https://access.redhat.com/errata/<errata_version>"
}
```


You can then begin adding multi-arch compute nodes to your cluster.
2. If you see the following output, then your cluster is not using the multi-architecture payload:

```terminal
{
 "url": "https://access.redhat.com/errata/<errata_version>"
}
```


[IMPORTANT]
----
To migrate your cluster so the cluster supports multi-architecture compute machines, follow the procedure in Migrating to a cluster with multi-architecture compute machines.
----

# Adding an ARM64 compute machine set to your cluster

To configure a cluster with multi-architecture compute machines, you must create a AWS ARM64 compute machine set. This adds ARM64 compute nodes to your cluster so that your cluster has multi-architecture compute machines.

* You installed the OpenShift CLI (oc).
* You used the installation program to create an AMD64 single-architecture AWS cluster with the multi-architecture installer binary.

* Create and modify a compute machine set, this will control the ARM64 compute nodes in your cluster.

```terminal
$ oc create -f aws-arm64-machine-set-0.yaml
```


```yaml
apiVersion: machine.openshift.io/v1beta1
kind: MachineSet
metadata:
  labels:
    machine.openshift.io/cluster-api-cluster: <infrastructure_id> 1
  name: <infrastructure_id>-aws-arm64-machine-set-0 1
  namespace: openshift-machine-api
spec:
  replicas: 1
  selector:
    matchLabels:
      machine.openshift.io/cluster-api-cluster: <infrastructure_id> 1
      machine.openshift.io/cluster-api-machineset: <infrastructure_id>-<role>-<zone> 2
  template:
    metadata:
      labels:
        machine.openshift.io/cluster-api-cluster: <infrastructure_id>
        machine.openshift.io/cluster-api-machine-role: <role> 3
        machine.openshift.io/cluster-api-machine-type: <role> 3
        machine.openshift.io/cluster-api-machineset: <infrastructure_id>-<role>-<zone> 2
    spec:
      metadata:
        labels:
          node-role.kubernetes.io/<role>: ""
      providerSpec:
        value:
          ami:
            id: ami-02a574449d4f4d280 4
          apiVersion: awsproviderconfig.openshift.io/v1beta1
          blockDevices:
            - ebs:
                iops: 0
                volumeSize: 120
                volumeType: gp2
          credentialsSecret:
            name: aws-cloud-credentials
          deviceIndex: 0
          iamInstanceProfile:
            id: <infrastructure_id>-worker-profile 1
          instanceType: m6g.xlarge 5
          kind: AWSMachineProviderConfig
          placement:
            availabilityZone: us-east-1a 6
            region: <region> 7
          securityGroups:
            - filters:
                - name: tag:Name
                  values:
                    - <infrastructure_id>-worker-sg 1
          subnet:
            filters:
              - name: tag:Name
                values:
                  - <infrastructure_id>-private-<zone>
          tags:
            - name: kubernetes.io/cluster/<infrastructure_id> 1
              value: owned
            - name: <custom_tag_name>
              value: <custom_tag_value>
          userDataSecret:
            name: worker-user-data
```

Specify the infrastructure ID that is based on the cluster ID that you set when you provisioned the cluster. If you have the OpenShift CLI installed, you can obtain the infrastructure ID by running the following command:

```terminal
$ oc get -o jsonpath=‘{.status.infrastructureName}{“\n”}’ infrastructure cluster
```

Specify the infrastructure ID, role node label, and zone.
Specify the role node label to add.
Specify an ARM64 supported Red Hat Enterprise Linux CoreOS (RHCOS) Amazon Machine Image (AMI) for your AWS zone for your OpenShift Container Platform nodes.

```terminal
$ oc get configmap/coreos-bootimages \
	  -n openshift-machine-config-operator \
	  -o jsonpath='{.data.stream}' | jq \
	  -r '.architectures.<arch>.images.aws.regions."<region>".image'
```

Specify an ARM64 supported machine type. For more information, refer to "Tested instance types for AWS 64-bit ARM"
Specify the zone, for example us-east-1a. Ensure that the zone you select offers 64-bit ARM machines.
Specify the region, for example, us-east-1. Ensure that the zone you select offers 64-bit ARM machines.

1. View the list of compute machine sets by entering the following command:

```terminal
$ oc get machineset -n openshift-machine-api
```


You can then see your created ARM64 machine set.
Example output

```terminal
NAME                                                DESIRED  CURRENT  READY  AVAILABLE  AGE
<infrastructure_id>-aws-arm64-machine-set-0                   2        2      2          2  10m
```

2. You can check that the nodes are ready and scheduable with the following command:

```terminal
$ oc get nodes
```


* Tested instance types for AWS 64-bit ARM